{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WBk0ZDWY-ff8"
   },
   "source": [
    "<table align=\"center\">\n",
    "\n",
    "  <td align=\"center\"><a target=\"_blank\" href=\"https://colab.research.google.com/github/a-rebmann/nlp4bpa/blob/main/nlp4bpa_tutorial_2023.ipynb\">\n",
    "        <img src=\"https://i.ibb.co/2P3SLwK/colab.png\"  style=\"padding-bottom:5px;\" />Run in Google Colab</a></td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "57knM8jrYZ2t"
   },
   "source": [
    "# NLP for BPA - Hands-on Exercises\n",
    "\n",
    "## Outline\n",
    "\n",
    "### 1. Event log analysis\n",
    "    1.1 Importing and analyzing an event log with LLMs and pm4py\n",
    "    1.2 Creating functions for custom tasks: action and object extraction from event labels using LLMs\n",
    "    1.3 Label standardization.\n",
    "    1.4 Action type categorization.\n",
    "\n",
    "### 2. Analyzing textual process descriptions\n",
    "    Imperative model extraction from text\n",
    "    \n",
    "### 3. Future of NLP for BPA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### API key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "oaik = \"sk-EJTrFxDPn8IySszc1HeNT3BlbkFJft6L5GKOKyGV########\"\n",
    "os.environ[\"OPENAI_API_KEY\"] = oaik"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How to obtain your own API key?\n",
    "To get your own key do th following \n",
    "1. Create an account on https://platform.openai.com (as of September 8 2023, new accounts get a budget of 18$ to get started)\n",
    "2. Log into your account\n",
    "3. In the top-right corner, click on your account\n",
    "4. Select \"View API keys\"\n",
    "5. Generate a key by clicking on \"Create new secret key\"\n",
    "6. Copy the generated key from the pop-up window and save it somewhere.\n",
    "\n",
    "To use the key in this notebook, just replace 'replace this with an OpenAI API key' by your key in the cell above.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Required installs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "LkaimNJfYZ2w"
   },
   "outputs": [],
   "source": [
    "# Required installs\n",
    "!pip install -q pm4py==2.7.3\n",
    "!pip install -q openai\n",
    "!pip install -q langchain[all]\n",
    "!pip install -q chromadb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Event log analysis\n",
    "\n",
    "In this hands-on exercise we will anaylze an event log using NLP techniques. In particular, we will analyze (a subset of) an [event log of a travel process](https://data.4tu.nl/datasets/db35afac-2133-40f3-a565-2dc77a9329a3) at a university, which was published in the context of the BPI Challenge 2020."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Importing and analyzing an event log with GPTs and pm4py\n",
    "\n",
    "In this part, we will use a [Generative Pre-trained Transformer (GPT)](https://openai.com) and [pm4py](https://pm4py.fit.fraunhofer.de) to analyze the real-life event log. \n",
    "\n",
    "<small>\n",
    "Alessandro Berti, Daniel Schuster, and Wil M. P. van der Aalst: Abstractions, Scenarios, and Prompt Definitions for Process Mining with LLMs: A Case Study. In: BPM 2023 Workshops.\n",
    "</small>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing an event log (Google Colab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/a-rebmann/nlp4bpa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing an example event log\n",
    "import pm4py\n",
    "travel_event_log = pm4py.read_xes(\"/content/nlp4bpa/content/PermitLog_small.xes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "travel_event_log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing an event log (locally)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing an example event log\n",
    "import pm4py\n",
    "travel_event_log = pm4py.read_xes(\"content/PermitLog_small.xes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "travel_event_log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Describing the process captured in an event log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans_desc = pm4py.openai.describe_process(travel_event_log, openai_model=\"gpt-3.5-turbo\", api_key=os.environ[\"OPENAI_API_KEY\"])\n",
    "print(ans_desc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This result is based on the following query, which abstracts the log to a directly-follows graph that is in turn described textually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pm4py.algo.querying.openai import log_to_dfg_descr\n",
    "d_query = log_to_dfg_descr.apply(travel_event_log, parameters={})\n",
    "d_query+= \"can you provide a description of the process?\"\n",
    "print(d_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking for potentially undesired behavior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans_ad = pm4py.openai.anomaly_detection(travel_event_log, openai_model=\"gpt-3.5-turbo\", api_key=os.environ[\"OPENAI_API_KEY\"])\n",
    "print(ans_ad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This result is obtained by a abstracting the event log to trace variants:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pm4py.algo.querying.openai import log_to_variants_descr\n",
    "a_query = log_to_variants_descr.apply(travel_event_log, parameters={})\n",
    "a_query += \"what are the main anomalies? An anomaly involves a strange ordering of the activities, or a significant amount of rework. Please only data and process specific considerations, not general considerations. Please sort the anomalies based on their seriousness.\"\n",
    "print(a_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Creating functions for custom tasks: action and object extraction from event labels using LLMs\n",
    "In this part, we will focus on an NPL task in the context of business process analysis.\n",
    "We will show how such a task can be implemented using GPTs without any fine-tuning.\n",
    "\n",
    "As an example, we will look at the extraction of business objecs and actions from event labels. \n",
    "The automated analysis of such labels based on traditional NLP techniques and based on transformers has been actively researched. It enables many downstream pre-processing tasks, such as the cleaning/standardization of activity labels and the automated assessment of the type of activity that is performed (we will explore both of these later in this notebook).\n",
    "\n",
    "The central part of creating such a function is the creation of a \"prompt\" for the GPT. Designing a prompt is essentially how you “program” a GPT model, usually by providing instructions or some examples of how to successfully complete a task.\n",
    "\n",
    "For our task, such a prompt can look like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_prompt = \"\"\"You are an expert activity label tagger system. \n",
    "Your task is to accept activity labels such as 'create purchase order' as input and provide a list of pairs, where each pair consists of the main action and the object it is applied on. \n",
    "For 'create purchase order', you would return [('create', 'purchase order')] and for 'purchase order' [('', 'purchase order')]. \n",
    "If actions are not provided as verbs, change them into verbs, e.g., for 'purchase order creation' you would hence return ('create', 'purchase order') as well. \n",
    "Also turn past tense actions into present tense ones, e.g., 'purchase order created' becomes ('create', 'purchase order') too. \n",
    "If multiple actions are applied to the same object, split this into multiple pairs, e.g., 'create and send purchase order' becomes [('create', 'purchase order'), ('send', 'purchase oder')]\n",
    "If there is additional information, e.g., about who is performing the action or about an IT system that is involved, discard that. \n",
    "If there are any special characters, just replace them with whitespace. \n",
    "\n",
    "Under no circumstances (!) put any other text in your answer, only a (possibly empty) list of pairs with nothing before or after. \n",
    "In each pair the (optional) action comes first, followed by the object (if any).\n",
    "If the activity label does not contain any actions, return an empty list , ie., []\n",
    "\n",
    "Here is the activity label that shall be tagged.\n",
    "Text:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we define the actual python function wrapping the task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_object_action_pairs_from_label(label, model=\"gpt-3.5-turbo\"):\n",
    "    label_promt = task_prompt + \" '\" + label.lower() + \"''\"\n",
    "    import openai\n",
    "    openai.api_key = os.environ[\"OPENAI_API_KEY\"]\n",
    "    messages = [{\"role\": \"user\", \"content\": label_promt}]\n",
    "    response = openai.ChatCompletion.create(model=model, messages=messages, temperature=0)\n",
    "    res = response[\"choices\"][0][\"message\"][\"content\"]\n",
    "    res = eval(res)\n",
    "    return res\n",
    "    \n",
    "extract_object_action_pairs_from_label(\"notification letter creation and approval\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Label standardization\n",
    "\n",
    "Next, we use the implementation of our custom task for preprocessing our event log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inspecting the unique labels of the event log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_labels = set(travel_event_log[\"concept:name\"].unique())\n",
    "print(len(unique_labels), \"unique activity labels are in the log.\")\n",
    "unique_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Applying the funtion to the event log\n",
    "Next, we apply the custom function to the distinct event labels of our event log and create a mapping from original label to a new label that only consistes of an action applied to an object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_mapping = {}\n",
    "for label in unique_labels:\n",
    "    processed_label = extract_object_action_pairs_from_label(label)\n",
    "    print(label, \"->\" , processed_label)\n",
    "    label_mapping[label] = \" \".join(processed_label[0] if len(processed_label) > 0 else \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_mapping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that not all labels could be processed properly by the GPT. One option is to provide more examples to it by changing the prompt. \n",
    "\n",
    "Still, we may improve performance by using dedicated techniques, e.g., an activity-label tagger based on a pretrained Language Model that was specifically fine-tuned fot he task at hand; see [here](https://hanvanderaa.com/wp-content/uploads/2022/08/IS2022-Enabling-semantics-aware-process-mining-through-the-automated-annotation-of-event-logs.pdf) for details and [here](https://gitlab.uni-mannheim.de/processanalytics/label-tagger) for an easy-to-use python package wrapping such a dedicated label tagger. Note that, to use the tagger, a bunch of python packages (> 1GB) and a relatively large model (500MB) are needed, which takes to long to install in the context of the live session."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Replacing the labels in the event log\n",
    "Having established this mapping, we can relace the original event lables with the ones obtained though our custom function.\n",
    "In this manner, we obtain simpler/standardized labels and reduce the number of total labels in the event log. The latter in turn can lead to simpler process models (due to fewer nodes) when applying process discovery.\n",
    "Also note that the role information (e.g., EMPLOYEE, SUPERVISOR, ADMINISTRATION) that we ommitted from the original labels in the standardization process are still available in the log, because these were already captured in the dedicated <code>org:role</code> attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "travel_event_log[\"concept:name\"] = travel_event_log[\"concept:name\"].apply(lambda x: x if label_mapping[x] == '' else label_mapping[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "travel_event_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_labels_preprocessed = set(travel_event_log[\"concept:name\"].unique())\n",
    "print(len(unique_labels_preprocessed), \"unique preprocessed activity labels are in the log.\")\n",
    "unique_labels_preprocessed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Activity type categorization\n",
    "Given the new/standardized event labels of our event log, we next want to aquire more information about the type of the activities executed in the process underlying the event log.\n",
    "\n",
    "Knowing about the type of an activity, e.g., if an activity captures the update of a request or the decision about the acceptance of a request, can be helpful for other analyisis tasks. \n",
    "For instance, in conformance checking we may want to assign a higher severity to conformance violations if these involve decisions than if they involve updates.\n",
    "\n",
    "We can create a prompt that desribes this task and define a function to wrap it as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_2_prompt = \"\"\"You are an expert activity label classification system. \n",
    "Your task is to accept activity labels such as 'create purchase order' as input and provide the \n",
    "category of the activity as output. The categories are 'decide', 'create', 'update', 'delete'.\n",
    "Do not put any other text in your answer, only a category with nothing before or after. \n",
    "If the activity label does not ccorrespond to any of these categories return 'other'.\n",
    "\n",
    "Here is the activity label that shall be tagged.\n",
    "Text:\n",
    "\"\"\"\n",
    "\n",
    "def categorize_activity(label, model=\"gpt-3.5-turbo\"):\n",
    "    label_promt = task_2_prompt + \"'\" + label.lower() + \"''\"\n",
    "    import openai\n",
    "    openai.api_key = os.environ[\"OPENAI_API_KEY\"]\n",
    "    messages = [{\"role\": \"user\", \"content\": label_promt}]\n",
    "    response = openai.ChatCompletion.create(model=model, messages=messages, temperature=0)\n",
    "    res = response[\"choices\"][0][\"message\"][\"content\"]\n",
    "    return res\n",
    "\n",
    "categorize_activity(\"approve declaration\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course these activity types are not set in stone and can be adjusted accoring to your preferences and analysis purpose. For instance, having an acticity type \"communicate\" may be beneficial for the analysis of handovers in the process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activity_categories = {}\n",
    "for label in unique_labels_preprocessed:\n",
    "    processed_label = categorize_activity(label)\n",
    "    print(label, \"->\" , processed_label)\n",
    "    activity_categories[label] = processed_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "travel_event_log[\"activity:category\"] = travel_event_log[\"concept:name\"].apply(lambda x: \"\" if x not in activity_categories else activity_categories[x])\n",
    "travel_event_log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Analyzing textual process descriptions\n",
    "\n",
    "In this hands-on exercise we will have LLMs extract imperative process models from textual process descriptions.\n",
    "We provide three examples of textual process descriptions taken from exercises in the [Fundamentals of Business Process Management Textbook](http://fundamentals-of-bpm.org) (Exercises 3.1-3.3). \n",
    "\n",
    "We will give these to a GPT model asking it to extract an imperative process model.\n",
    "Technically, GPT models can generate markup output such as BPMN-XML. This is (currently) not practical, though. Due to the verbosity of XML, the output limit of GPTs prevents the direct generation of complete XML-code even for small BPMN diagrams. Also, after several attempts (on small models), we did not obtain XML code such that it could be displayed by a (commercial) BPMN modeling tool. \n",
    "\n",
    "Therefore, we will create a propt that defines an intermediate notation that the LLM shall use to capture the imperative process model. This intermediate notiation only captures tasks, arcs, and gateways (AND, XOR, and OR).\n",
    "\n",
    "We give the prompt including the textual process description to the LLM and obtain a \"model\". We then compare this result to a process model created by a humal modeling expert for the respective description. Note that naturally there are multiple valid options on how to model a process based on natural language text.\n",
    "\n",
    "These are the descriptions we will use:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>2.1</b>: Once a loan application has been approved by the loan provider, an acceptance pack is prepared and sent to the customer. The acceptance pack includes a repayment schedule which the customer needs to agree upon by sending the signed documents back to the loan provider. The latter then verifies the repayment agreement: if the applicant disagreed with the repayment schedule, the loan provider cancels the application; if the applicant agreed, the loan provider approves the application. In either case, the process completes with the loan provider notifying the applicant of the application status.\n",
    "\n",
    "<b>2.2</b>: A loan application is approved if it passes two checks: (i) the applicant’s loan risk assessment, done automatically by a system, and (ii) the appraisal of the property for which the loan has been asked, carried out by a property appraiser. The risk assessment requires a credit history check on the applicant, which is performed by a financial officer. Once both the loan risk assessment and the property appraisal have been performed, a loan officer can assess the applicant’s eligibility. If the applicant is not eligible, the application is rejected, otherwise the acceptance pack is prepared and sent to the applicant.\n",
    "\n",
    "<b>2.3</b>: A loan application may be coupled with a home insurance which is offered at discounted prices. The applicants may express their interest in a home insurance plan at the time of submitting their loan application to the loan provider. Based on this information, if the loan application is approved, the loan provider may either only send an acceptance pack to the applicant, or also send a home insurance quote. The process then continues with the verification of the repayment agreement.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_description_3_1 = \"Once a loan application has been approved by the loan provider, an acceptance pack is prepared and sent to the customer. The acceptance pack includes a repayment schedule which the customer needs to agree upon by sending the signed documents back to the loan provider. The latter then verifies the repayment agreement: if the applicant disagreed with the repayment schedule, the loan provider cancels the application; if the applicant agreed, the loan provider approves the application. In either case, the process completes with the loan provider notifying the applicant of the application status.\"\n",
    "process_description_3_2 = \"A loan application is approved if it passes two checks: (i) the applicant’s loan risk assessment, done automatically by a system, and (ii) the appraisal of the property for which the loan has been asked, carried out by a property appraiser. The risk assessment requires a credit history check on the applicant, which is performed by a financial officer. Once both the loan risk assessment and the property appraisal have been performed, a loan officer can assess the applicant’s eligibility. If the applicant is not eligible, the application is rejected, otherwise the acceptance pack is prepared and sent to the applicant.\"\n",
    "process_description_3_3 = \"A loan application may be coupled with a home insurance which is offered at discounted prices. The applicants may express their interest in a home insurance plan at the time of submitting their loan application to the loan provider. Based on this information, if the loan application is approved, the loan provider may either only send an acceptance pack to the applicant, or also send a home insurance quote. The process then continues with the verification of the repayment agreement.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_to_intermediate_prompt = \"\"\"\n",
    "create a BPMN process model for the process description that I’ll give to you. Do not consider tasks of external parties.\n",
    "Use the following notation for control-flow constructs in your output:\n",
    "1. Tasks, i.e., the basic construct, represent tasks as words in a verb-object style, e.g., receive order, when possible.\n",
    "2. (Potentially nested) constructs:\n",
    "2.1 Sequences denoted as ->(construct1, construct2, ...), which means that construct1 is followed by construct2 and construct2 is followed by ...\n",
    "2.2 XOR construct as XOR(construct1, construct2, ...), which resembles XOR gateways. In case of XOR, provide me with the condition of using its elements using this notation: XOR([condition]construct1, [condition]construct2, ...).\n",
    "2.3 OR construct OR(construct1, construct2, ...), which resembles OR gateways.\n",
    "2.4 AND construct AND(construct1, construct2, ...), which resembles AND gateways.\n",
    "Do not include any line breaks or textual explanation in your output and stick to the provided notation.\n",
    "\"\"\"\n",
    "\n",
    "# The prompt below can be used to play around with the LLMs capabilities to generate actual BPMN-XML \n",
    "# (which does not really work well yet, as explained above.)\n",
    "text_to_bpmn_prompt = \"Convert the given description into a BPMN diagram and provide the XML code for it. Provide only the code and nothing else.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_model(description, model=\"gpt-3.5-turbo\", xml=False):\n",
    "    prompt = text_to_bpmn_prompt if xml else text_to_intermediate_prompt + \"\\n Here is the description:\\n\" + description\n",
    "    import openai\n",
    "    openai.api_key = os.environ[\"OPENAI_API_KEY\"]\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    response = openai.ChatCompletion.create(model=model, messages=messages, temperature=0)\n",
    "    return response[\"choices\"][0][\"message\"][\"content\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the model provided by a human expert:\n",
    "<img src=\"https://raw.githubusercontent.com/a-rebmann/nlp4bpa/main/content/exercise_3_1.png\" alt=\"Exercise 3.1\" />\n",
    "\n",
    "This is what the GPT comes up with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans_sketch = text_to_model(process_description_3_1)\n",
    "print(ans_sketch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the model provided by a human expert:\n",
    "<img src=\"https://raw.githubusercontent.com/a-rebmann/nlp4bpa/main/content/exercise_3_2.png\" alt=\"Exercise 3.2\" />\n",
    "\n",
    "This is what the GPT comes up with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans_sketch = text_to_model(process_description_3_2)\n",
    "print(ans_sketch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the model provided by a human expert:\n",
    "<img src=\"https://raw.githubusercontent.com/a-rebmann/nlp4bpa/main/content/exercise_3_3.png\" alt=\"Exercise 3.3\" />\n",
    "\n",
    "This is what the GPT comes up with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans_sketch = text_to_model(process_description_3_3)\n",
    "print(ans_sketch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## 3. Future of NLP for BPA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "A conceptual architecture of an **Large Process Models (LPM)** \n",
    "\n",
    "<img src=\"content/LPM_architecture.png\" alt=\"LPM\" />\n",
    "Kampik et. al., 2023 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<b>Exercise 4 : Data connection exercise</b> - Ask a Company Process Bot about the internal processes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Your function should do the following:\n",
    "\n",
    "* **Document Loading:** Read the example_process_descriptions.txt file inside the content folder\n",
    "* **Splitting:** Split this into chunks (you choose the size)\n",
    "* **Storage:** Write this to a ChromaDB Vector Store\n",
    "* **Retrieval:** Use Context Compression to return the relevant portion of the document to the question\n",
    "\n",
    "<img src=\"content/exercise_4.png\" alt=\"Exercise 4\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 1047, which is longer than the specified 200\n",
      "Created a chunk of size 858, which is longer than the specified 200\n"
     ]
    }
   ],
   "source": [
    "# import\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.retrievers.document_compressors import LLMChainExtractor \n",
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "\n",
    "# PART ONE:\n",
    "# LOAD \"content/example_process_descriptions\" in a Document object\n",
    "loader = TextLoader(\"/content/nlp4bpa/content/example_process_descriptions.txt\")\n",
    "documents = loader.load()\n",
    "\n",
    "# PART TWO\n",
    "# Split the document into chunks (you choose how and what size)\n",
    "text_splitter = CharacterTextSplitter(chunk_size=200, chunk_overlap=50)\n",
    "docs = text_splitter.split_documents(documents)\n",
    "\n",
    "# PART THREE\n",
    "# EMBED THE Documents (now in chunks) to a persisted ChromaDB\n",
    "embedding_function = OpenAIEmbeddings()#SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "db = Chroma.from_documents(docs, embedding_function)\n",
    "\n",
    "#PART FOUR \n",
    "# query it\n",
    "query = \"What is the first step in the claim handling process?\"\n",
    "llm = ChatOpenAI(temperature=0)\n",
    "compressor = LLMChainExtractor.from_llm(llm)\n",
    "compression_retriever = ContextualCompressionRetriever(base_compressor=compressor, \n",
    "                                                       base_retriever=db.as_retriever())\n",
    "compressed_docs = compression_retriever.get_relevant_documents(query)\n",
    "compressed_docs[0].page_content # NEED TO COMPRESS THESE RESULTS!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "WBk0ZDWY-ff8"
   ],
   "name": "nlp4bpm_tutorial_2023.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
