{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WBk0ZDWY-ff8"
   },
   "source": [
    "<table align=\"center\">\n",
    "\n",
    "  <td align=\"center\"><a target=\"_blank\" href=\"https://colab.research.google.com/github/a-rebmann/nlp4bpa/blob/main/nlp4bpa_tutorial_2023.ipynb\">\n",
    "        <img src=\"https://i.ibb.co/2P3SLwK/colab.png\"  style=\"padding-bottom:5px;\" />Run in Google Colab</a></td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "57knM8jrYZ2t"
   },
   "source": [
    "# NLP for BPA - Hands-on Exercises\n",
    "\n",
    "## Outline\n",
    "\n",
    "### 1. Event log and Process Model Analysis\n",
    "    1.1 Importing and analyzing an event log with GPT4 and pm4py\n",
    "    1.2 Custom task: action and object extraction from activity labels using LLMs\n",
    "    1.3 Potential use cases of the custom task.\n",
    "\n",
    "### 2. Analyzing textual process descriptions\n",
    "    Imperative model extraction from text\n",
    "    \n",
    "### 3. Future of NLP for BPA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### API key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Required installs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LkaimNJfYZ2w"
   },
   "outputs": [],
   "source": [
    "# Required installs\n",
    "\n",
    "!pip install -q pm4py==2.7.3\n",
    "!pip install -q spacy\n",
    "!pip install -q spacy-transformers\n",
    "!pip install -q openai\n",
    "!python -m spacy download en_core_web_sm\n",
    "!python -m pip install spacy-llm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Importing and analyzing an event log with GPTs and pm4py\n",
    "\n",
    "In this part, we will use [GPT-4](https://openai.com) and [pm4py](https://pm4py.fit.fraunhofer.de) to analyze a real-life event log. \n",
    "\n",
    "<small>\n",
    "Alessandro Berti, Daniel Schuster, and Wil M. P. van der Aalst: Abstractions, Scenarios, and Prompt Definitions for Process Mining with LLMs: A Case Study. In: BPM 2023 Workshops.\n",
    "</small>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing an event log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing an example event log\n",
    "\n",
    "import pm4py\n",
    "travel_event_log = pm4py.read_xes(\"content/PermitLog.xes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Describing the process captured in an event log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans_desc = pm4py.openai.describe_process(travel_event_log, openai_model=\"gpt-3.5-turbo\", api_key=os.environ[\"OPENAI_API_KEY\"])\n",
    "print(ans_desc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This result is based on the following query, which abstracts the log to a directly-follows graph that is in turn described textually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pm4py.algo.querying.openai import log_to_variants_descr\n",
    "d_query = log_to_dfg_descr.apply(travel_event_log, parameters={})\n",
    "d_query+= \"can you provide a description of the process?\"\n",
    "print(d_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking for potentially undesired behavior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans_ad = pm4py.openai.anomaly_detection(travel_event_log, openai_model=\"gpt-3.5-turbo\", api_key=os.environ[\"OPENAI_API_KEY\"])\n",
    "print(ans_ad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This result is obtained by a abstracting the event log to trace variants:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pm4py.algo.querying.openai import log_to_dfg_descr\n",
    "a_query = log_to_variants_descr.apply(log_obj, parameters={})\n",
    "a_query += \"what are the main anomalies? An anomaly involves a strange ordering of the activities, or a significant amount of rework. Please only data and process specific considerations, not general considerations. Please sort the anomalies based on their seriousness.\"\n",
    "print(a_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Implementing a custom task using GPTs\n",
    "In this part, we will focus on an NPL task in the context of business process analysis.\n",
    "We will show how such a task can be implemented using LLMs without any fine-tuning.\n",
    "\n",
    "As an example, we will focus on the extraction of business objecs and actions applied to these from activity or event labels. \n",
    "The automated analysis of such labels based on traditional NLP techniques and based on transformers has been actively researched. It enables many downstream pre-processing tasks, such as the cleaning/standardization of activity labels and the automated assessment of the type of activity that is performed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_prompt = \"\"\"You are an expert activity label tagger system. \n",
    "Your task is to accept activity labels such as 'create purchase order' as input and provide a list of pairs, where each pair consists of an action and the object it is applied on. \n",
    "For 'create purchase order', you would return [('create', 'purchase oder')]. \n",
    "If actions are not provided as verbs, change them into verbs. \n",
    "For 'purchase order creation' you would hence return ('create', 'purchase order') as well and for 'purchase order for checking' you would return ('check', 'purchase order'). \n",
    "Also turn past tense actions into present tense ones, i.e. 'purchase order created' becomes ('create', 'purchase order') too. \n",
    "If there is additional information, e.g., about who is performing the action orabout an IT system that is involved, discard that. \n",
    "\n",
    "Do not put any other text in your answer, only a (possibly empty) list of pairs with nothing before or after. In each pair the action comes first, followed by the object (if any).\n",
    "If the activity label does not contain any actions, return an empty list , ie., []\n",
    "\n",
    "Here is the activity label that shall be tagged.\n",
    "Text:\n",
    "\"\"\"\n",
    "\n",
    "def extract_object_action_pairs_from_label(label, model=\"gpt-3.5-turbo\"):\n",
    "    label_promt = task_prompt + \"'\" + label.lower() + \"''\"\n",
    "    import openai\n",
    "    openai.api_key = os.environ[\"OPENAI_API_KEY\"]\n",
    "    messages = [{\"role\": \"user\", \"content\": label_promt}]\n",
    "    response = openai.ChatCompletion.create(model=model, messages=messages)\n",
    "    return response[\"choices\"][0][\"message\"][\"content\"]\n",
    "    \n",
    "extract_object_action_pairs_from_label(\"notification letter creation and approval\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Potential use cases of the custom task\n",
    "\n",
    "Next, we use the implementation of our custom task for preprocessing our event log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's apply the function to the event labels of our event log."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_labels = set(travel_event_log[\"concept:name\"].unique())\n",
    "unique_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_mapping = {}\n",
    "for label in unique_labels:\n",
    "    processed_label = extract_object_action_pairs_from_label(label)\n",
    "    print(processed_label)\n",
    "    label_mapping[label] = \" \".join(processed_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Analyzing textual process descriptions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Exercise 3.1</b>: Once a loan application has been approved by the loan provider, an acceptance pack is prepared and sent to the customer. The acceptance pack includes a repayment schedule which the customer needs to agree upon by sending the signed documents back to the loan provider. The latter then verifies the repayment agreement: if the applicant disagreed with the repayment schedule, the loan provider cancels the application; if the applicant agreed, the loan provider approves the application. In either case, the process completes with the loan provider notifying the applicant of the application status.\n",
    "\n",
    "<b>Exercise 3.2</b>: A loan application is approved if it passes two checks: (i) the applicantâ€™s loan risk assessment, done automatically by a system, and (ii) the appraisal of the property for which the loan has been asked, carried out by a property appraiser. The risk assessment requires a credit history check on the applicant, which is performed by a financial officer. Once both the loan risk assessment and the property appraisal have been performed, a loan officer can assess the applicantâ€™s eligibility. If the applicant is not eligible, the application is rejected, otherwise the acceptance pack is prepared and sent to the applicant.\n",
    "\n",
    "<b>Exercise 3.3</b>: A loan application may be coupled with a home insurance which is offered at discounted prices. The applicants may express their interest in a home insurance plan at the time of submitting their loan application to the loan provider. Based on this information, if the loan application is approved, the loan provider may either only send an acceptance pack to the applicant, or also send a home insurance quote. The process then continues with the verification of the repayment agreement.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exercise_3_1 = \"Once a loan application has been approved by the loan provider, an acceptance pack is prepared and sent to the customer. The acceptance pack includes a repayment schedule which the customer needs to agree upon by sending the signed documents back to the loan provider. The latter then verifies the repayment agreement: if the applicant disagreed with the repayment schedule, the loan provider cancels the application; if the applicant agreed, the loan provider approves the application. In either case, the process completes with the loan provider notifying the applicant of the application status.\"\n",
    "exercise_3_2 = \"A loan application is approved if it passes two checks: (i) the applicantâ€™s loan risk assessment, done automatically by a system, and (ii) the appraisal of the property for which the loan has been asked, carried out by a property appraiser. The risk assessment requires a credit history check on the applicant, which is performed by a financial officer. Once both the loan risk assessment and the property appraisal have been performed, a loan officer can assess the applicantâ€™s eligibility. If the applicant is not eligible, the application is rejected, otherwise the acceptance pack is prepared and sent to the applicant.\"\n",
    "exercise_3_3 = \"A loan application may be coupled with a home insurance which is offered at discounted prices. The applicants may express their interest in a home insurance plan at the time of submitting their loan application to the loan provider. Based on this information, if the loan application is approved, the loan provider may either only send an acceptance pack to the applicant, or also send a home insurance quote. The process then continues with the verification of the repayment agreement.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_to_intermediate_prompt = \"\"\"\n",
    "create a BPMN process model for the process description that Iâ€™ll give to you. Do not consider tasks of external parties.\n",
    "Use the following notation for control-flow constructs in your output\n",
    "1. Tasks, i.e., the basic construct, represent tasks as words in a verb-object style, e.g., receive order, when posiible.\n",
    "2. Nested constructs:\n",
    "2.1 Sequences denoted as ->(construct1, construct2, ...), which means that construct1 is followed by construct2 and construct2 is followed by ...\n",
    "2.2 XOR construct as XOR(construct1, construct2, ...), in case of XOR, provide me with the condition of using its elements using this notation: XOR([condition]construct1, [condition]construct2,...).\n",
    "2.3 OR construct OR(construct1, construct2, ...)\n",
    "2.4 AND construct AND(construct1, construct2, ...) \n",
    "Do not include any line breaks or textual explanation in you output and stick to the provided notation.\n",
    "\"\"\"\n",
    "\n",
    "text_to_bpmn_prompt = \"Convert the given description into a BPMN diagram and provide the XML code for it. Provide only the code and nothing else.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_model(description, model=\"gpt-3.5-turbo\", xml=False):\n",
    "    prompt = text_to_bpmn_prompt if xml else text_to_intermediate_prompt + \"\\n Here is the description:\\n\" + description\n",
    "    import openai\n",
    "    openai.api_key = os.environ[\"OPENAI_API_KEY\"]\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    response = openai.ChatCompletion.create(model=model, messages=messages)\n",
    "    return response[\"choices\"][0][\"message\"][\"content\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the model provided by a human expert:\n",
    "<img src=\"https://raw.githubusercontent.com/a-rebmann/nlp4bpa/main/content/exercise_3_1.png\" alt=\"Exercise 3.1\" />\n",
    "\n",
    "This is what GPT-X comes up with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans_sketch = text_to_model(exercise_3_1)\n",
    "print(ans_sketch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the model provided by a human expert:\n",
    "<img src=\"https://raw.githubusercontent.com/a-rebmann/nlp4bpa/main/content/exercise_3_2.png\" alt=\"Exercise 3.2\" />\n",
    "\n",
    "This is what GPT-X comes up with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans_sketch = text_to_model(exercise_3_2)\n",
    "print(ans_sketch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the model provided by a human expert:\n",
    "<img src=\"https://raw.githubusercontent.com/a-rebmann/nlp4bpa/main/content/exercise_3_3.png\" alt=\"Exercise 3.3\" />\n",
    "\n",
    "This is what GPT-X comes up with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans_sketch = text_to_model(exercise_3_3)\n",
    "print(ans_sketch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "WBk0ZDWY-ff8"
   ],
   "name": "nlp4bpm_tutorial_2023.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
